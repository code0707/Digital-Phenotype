{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b3bdd0-919c-4b81-8bb3-8a78a0af87d9",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071ec102-617c-4bab-b6ce-a2e9966b8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate, ShiftScaleRotate, GlassBlur, GaussNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dbb6354-c197-493b-a38d-9a731d63355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create a directory \"\"\"\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0bad240-4680-420b-a705-3704a1f00e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    train_x = sorted(glob(os.path.join(path, \"training\", \"images\", \"*.tif\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"training\", \"1st_manual\", \"*.gif\")))\n",
    "    \n",
    "    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.tif\")))\n",
    "    test_y = sorted(glob(os.path.join(path, \"test\", \"1st_manual\", \"*.gif\")))\n",
    "    \n",
    "    return (train_x,train_y),(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "100f4b9f-9ecf-40db-b1cd-a474ba0f3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(images, masks, save_path, augment = True):\n",
    "    size = (512,512)\n",
    "    \n",
    "    for idx, (x,y) in tqdm(enumerate(zip(images, masks)),total=len(images)):\n",
    "        \"\"\" Extracting the name \"\"\"\n",
    "        name = x.split(\"/\")[:-1]+x.split(\"/\")[-1].split(\"\\\\\")\n",
    "        name = name[-1].split(\".\")[0]\n",
    "        \n",
    "        \"\"\" Reading image and mask \"\"\"\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        y = imageio.mimread(y)[0]\n",
    "        \n",
    "        if augment == True:\n",
    "            aug = HorizontalFlip(p=1.0)\n",
    "            augmented = aug(image=x,mask=y)\n",
    "            x1 = augmented[\"image\"]\n",
    "            y1 = augmented[\"mask\"]\n",
    "            \n",
    "            aug = VerticalFlip(p=1.0)\n",
    "            augmented = aug(image=x,mask=y)\n",
    "            x2 = augmented[\"image\"]\n",
    "            y2 = augmented[\"mask\"]\n",
    "            \n",
    "            aug = Rotate(limit=45,p=1.0)\n",
    "            augmented = aug(image=x,mask=y)\n",
    "            x3 = augmented[\"image\"]\n",
    "            y3 = augmented[\"mask\"]\n",
    "            \n",
    "            aug = GaussNoise(p=1.0)\n",
    "            augmented = aug(image=x,mask=y)\n",
    "            x4 = augmented[\"image\"]\n",
    "            y4 = augmented[\"mask\"]\n",
    "            \n",
    "            aug = ShiftScaleRotate(p=1.0)\n",
    "            augmented = aug(image=x,mask=y)\n",
    "            x5 = augmented[\"image\"]\n",
    "            y5 = augmented[\"mask\"]\n",
    "            \n",
    "            aug = GlassBlur(p=1.0)\n",
    "            augmented = aug(image=x,mask=y)\n",
    "            x6 = augmented[\"image\"]\n",
    "            y6 = augmented[\"mask\"]\n",
    "            \n",
    "            X = [x,x1,x2,x3,x4,x5,x6]\n",
    "            Y = [y,y1,y2,y3,x4,x5,x6]\n",
    "            \n",
    "        else:\n",
    "            X = [x]\n",
    "            Y = [y]\n",
    "            \n",
    "        index = 0    \n",
    "        for i,m in zip(X,Y):\n",
    "            i = cv2.resize(i,size)\n",
    "            m = cv2.resize(m,size)  \n",
    "            \n",
    "            tmp_image_name = f\"{name}_{index}.png\"\n",
    "            tmp_mask_name = f\"{name}_{index}.png\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, \"image\", tmp_image_name)\n",
    "            mask_path = os.path.join(save_path, \"mask\", tmp_mask_name)\n",
    "            \n",
    "            cv2.imwrite(image_path, i)\n",
    "            cv2.imwrite(mask_path, m)\n",
    "            \n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbe0088-818f-44d9-ae30-b2198291c243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.65it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 31.50it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    \"\"\" Load the data \"\"\"\n",
    "    data_path = \"C:/Users/hp/Desktop/datasets\"\n",
    "    (train_x,train_y),(test_x,test_y) = load_data(data_path)\n",
    "    \n",
    "    \"\"\" Create directories to save augumented data\"\"\"\n",
    "    create_dir(\"C:/Users/hp/Desktop/aug_data/train/image/\")\n",
    "    create_dir(\"C:/Users/hp/Desktop/aug_data/train/mask/\")\n",
    "    create_dir(\"C:/Users/hp/Desktop/aug_data/test/image/\")\n",
    "    create_dir(\"C:/Users/hp/Desktop/aug_data/test/mask/\")\n",
    "    \n",
    "    \"\"\" Data Augmentation \"\"\"\n",
    "    augment_data(train_x,train_y,\"C:/Users/hp/Desktop/aug_data/train\",augment=True)\n",
    "    augment_data(test_x,test_y,\"C:/Users/hp/Desktop/aug_data/test\",augment=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a0fcb-75ea-455a-b106-c51b4e17e052",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f7e9950-64c0-431b-b609-c1654c6e2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f148ab-dc6d-4acf-906a-519448f52014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_c,out_c):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_c,out_c,kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_c)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_c,out_c,kernel_size=3,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_c)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8376a83d-89c0-47e1-8843-ed531320a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c,out_c):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = conv_block(in_c,out_c)\n",
    "        self.pool = nn.MaxPool2d((2,2))\n",
    "                \n",
    "    def forward(self,inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "                \n",
    "        return x,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cbd5223-0f96-452a-836b-598d7da33eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv = conv_block(out_c+out_c, out_c)\n",
    "\n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3f81df8-d8bc-48be-8a9b-1bfc5c5c1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class build_unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        self.e1 = encoder_block(3, 64)\n",
    "        self.e2 = encoder_block(64, 128)\n",
    "        self.e3 = encoder_block(128, 256)\n",
    "        self.e4 = encoder_block(256, 512)\n",
    "\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        self.b = conv_block(512, 1024)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(1024, 512)\n",
    "        self.d2 = decoder_block(512, 256)\n",
    "        self.d3 = decoder_block(256, 128)\n",
    "        self.d4 = decoder_block(128, 64)\n",
    "\n",
    "        \"\"\" Classifier \"\"\"\n",
    "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        s1, p1 = self.e1(inputs)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        b = self.b(p4)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, s4)\n",
    "        d2 = self.d2(d1, s3)\n",
    "        d3 = self.d3(d2, s2)\n",
    "        d4 = self.d4(d3, s1)\n",
    "\n",
    "        outputs = self.outputs(d4)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27eb22a5-b759-4b5b-81cb-b4ab39809a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\new\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    x = torch.randn((2, 3, 512, 512))\n",
    "    f = build_unet()\n",
    "    y = f(x)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718a05fd-748c-495f-b15d-6a273c9a3d40",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f0fff85-c2b0-49cb-aa12-cd60c418fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "\"\"\" Seeding the randomness. \"\"\"\n",
    "def seeding(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\"\"\" Create a directory. \"\"\"\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\"\"\" Calculate the time taken \"\"\"\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c44ef34-f212-4843-a815-01bf5d7e68d5",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbf11fbd-e719-461c-814a-6b69fa04e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "\n",
    "        return Dice_BCE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ce967-404c-4307-818e-b70192007ad3",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f91a7f2a-9da5-4ad7-b9a4-71af8b05704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "#import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DriveDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path):\n",
    "\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.n_samples = len(images_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Reading image \"\"\"\n",
    "        image = cv2.imread(self.images_path[index], cv2.IMREAD_COLOR)\n",
    "        image = image/255.0 ## (512, 512, 3)\n",
    "        image = np.transpose(image, (2, 0, 1))  ## (3, 512, 512)\n",
    "        image = image.astype(np.float32)\n",
    "        image = torch.from_numpy(image)\n",
    "\n",
    "        \"\"\" Reading mask \"\"\"\n",
    "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask/255.0   ## (512, 512)\n",
    "        mask = np.expand_dims(mask, axis=0) ## (1, 512, 512)\n",
    "        mask = mask.astype(np.float32)\n",
    "        mask = torch.from_numpy(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb91846-a3ab-48f4-b183-ba070e273cfa",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f6c244-3f40-44fd-b0cf-e9bf5272b045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size:\n",
      "Train: 140 - Valid: 20\n",
      "\n",
      "Valid loss improved from inf to 1.2382. Saving checkpoint: files/checkpoint.pth\n",
      "Epoch: 01 | Epoch Time: 24m 19s\n",
      "\tTrain Loss: 1.186\n",
      "\t Val. Loss: 1.238\n",
      "\n",
      "Valid loss improved from 1.2382 to 1.0249. Saving checkpoint: files/checkpoint.pth\n",
      "Epoch: 02 | Epoch Time: -33m -47s\n",
      "\tTrain Loss: 1.098\n",
      "\t Val. Loss: 1.025\n",
      "\n",
      "Epoch: 03 | Epoch Time: 33m 50s\n",
      "\tTrain Loss: 1.084\n",
      "\t Val. Loss: 1.045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "#from data import DriveDataset\n",
    "#from model import build_unet\n",
    "\n",
    "def train(model, loader, optimizer, loss_fn, device):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, dtype=torch.float32)\n",
    "        y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss = epoch_loss/len(loader)\n",
    "    return epoch_loss\n",
    "\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss = epoch_loss/len(loader)\n",
    "    return epoch_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    seeding(42)\n",
    "\n",
    "    \"\"\" Directories \"\"\"\n",
    "    create_dir(\"files\")\n",
    "\n",
    "    \"\"\" Load dataset \"\"\"\n",
    "    train_x = sorted(glob(\"C:/Users/hp/Desktop/aug_data/train/image/*\"))\n",
    "    train_y = sorted(glob(\"C:/Users/hp/Desktop/aug_data/train/mask/*\"))\n",
    "\n",
    "    valid_x = sorted(glob(\"C:/Users/hp/Desktop/aug_data/test/image/*\"))\n",
    "    valid_y = sorted(glob(\"C:/Users/hp/Desktop/aug_data/test/mask/*\"))\n",
    "    \n",
    "    train_x = list(pd.Series(train_x).apply(lambda i:\"/\".join(i.split(\"\\\\\"))))\n",
    "    train_y = list(pd.Series(train_y).apply(lambda i:\"/\".join(i.split(\"\\\\\"))))\n",
    "    valid_x = list(pd.Series(valid_x).apply(lambda i:\"/\".join(i.split(\"\\\\\"))))\n",
    "    valid_y = list(pd.Series(valid_y).apply(lambda i:\"/\".join(i.split(\"\\\\\"))))\n",
    "\n",
    "    data_str = f\"Dataset Size:\\nTrain: {len(train_x)} - Valid: {len(valid_x)}\\n\"\n",
    "    print(data_str)\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    H = 512\n",
    "    W = 512\n",
    "    size = (H, W)\n",
    "    batch_size = 2\n",
    "    num_epochs = 50\n",
    "    lr = 1e-4\n",
    "    checkpoint_path = \"files/checkpoint.pth\"\n",
    "\n",
    "    \"\"\" Dataset and loader \"\"\"\n",
    "    train_dataset = DriveDataset(train_x, train_y)\n",
    "    valid_dataset = DriveDataset(valid_x, valid_y)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cpu\")   \n",
    "    model = build_unet()\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
    "    loss_fn = DiceBCELoss()\n",
    "\n",
    "    \"\"\" Training the model \"\"\"\n",
    "    best_valid_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
    "        valid_loss = evaluate(model, valid_loader, loss_fn, device)\n",
    "\n",
    "        \"\"\" Saving the model \"\"\"\n",
    "        if valid_loss < best_valid_loss:\n",
    "            data_str = f\"Valid loss improved from {best_valid_loss:2.4f} to {valid_loss:2.4f}. Saving checkpoint: {checkpoint_path}\"\n",
    "            print(data_str)\n",
    "\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        data_str = f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\\n'\n",
    "        data_str += f'\\tTrain Loss: {train_loss:.3f}\\n'\n",
    "        data_str += f'\\t Val. Loss: {valid_loss:.3f}\\n'\n",
    "        print(data_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e7e46-31b0-496b-a049-f4bd5ad9f376",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "221753ee-1147-47f1-b8a1-c7e589c1642c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:08<00:00,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard: 0.6700 - F1: 0.8022 - Recall: 0.8387 - Precision: 0.7738 - Acc: 0.9641\n",
      "FPS:  0.3353587096856677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import os, time\n",
    "from operator import add\n",
    "import numpy as npzy\n",
    "from glob import glob\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\" Ground truth \"\"\"\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_true = y_true > 0.5\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    y_true = y_true.reshape(-1)\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_pred = y_pred.astype(np.uint8)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    score_jaccard = jaccard_score(y_true, y_pred)\n",
    "    score_f1 = f1_score(y_true, y_pred)\n",
    "    score_recall = recall_score(y_true, y_pred)\n",
    "    score_precision = precision_score(y_true, y_pred)\n",
    "    score_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return [score_jaccard, score_f1, score_recall, score_precision, score_acc]\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)    ## (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  ## (512, 512, 3)\n",
    "    return mask\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    seeding(42)\n",
    "\n",
    "    \"\"\" Folders \"\"\"\n",
    "    create_dir(\"results\")\n",
    "\n",
    "    \"\"\" Load dataset \"\"\"\n",
    "      \n",
    "    test_x = sorted(glob(\"C:/Users/hp/Desktop/aug_data/test/image/*\"))\n",
    "    test_y = sorted(glob(\"C:/Users/hp/Desktop/aug_data/test/mask/*\"))\n",
    "    \n",
    "    test_x = list(pd.Series(test_x).apply(lambda i:\"/\".join(i.split(\"\\\\\"))))\n",
    "    test_y = list(pd.Series(test_y).apply(lambda i:\"/\".join(i.split(\"\\\\\"))))\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    H = 512\n",
    "    W = 512\n",
    "    size = (W, H)\n",
    "    checkpoint_path = \"files/checkpoint.pth\"\n",
    "\n",
    "    \"\"\" Load the checkpoint \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = build_unet()\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    time_taken = []\n",
    "\n",
    "    for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
    "        \"\"\" Extract the name \"\"\"\n",
    "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        \"\"\" Reading image \"\"\"\n",
    "        image = cv2.imread(x, cv2.IMREAD_COLOR) ## (512, 512, 3)\n",
    "        ## image = cv2.resize(image, size)\n",
    "        x = np.transpose(image, (2, 0, 1))      ## (3, 512, 512)\n",
    "        x = x/255.0\n",
    "        x = np.expand_dims(x, axis=0)           ## (1, 3, 512, 512)\n",
    "        x = x.astype(np.float32)\n",
    "        x = torch.from_numpy(x)\n",
    "        x = x.to(device)\n",
    "\n",
    "        \"\"\" Reading mask \"\"\"\n",
    "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
    "        ## mask = cv2.resize(mask, size)\n",
    "        y = np.expand_dims(mask, axis=0)            ## (1, 512, 512)\n",
    "        y = y/255.0\n",
    "        y = np.expand_dims(y, axis=0)               ## (1, 1, 512, 512)\n",
    "        y = y.astype(np.float32)\n",
    "        y = torch.from_numpy(y)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \"\"\" Prediction and Calculating FPS \"\"\"\n",
    "            start_time = time.time()\n",
    "            pred_y = model(x)\n",
    "            pred_y = torch.sigmoid(pred_y)\n",
    "            total_time = time.time() - start_time\n",
    "            time_taken.append(total_time)\n",
    "\n",
    "\n",
    "            score = calculate_metrics(y, pred_y)\n",
    "            metrics_score = list(map(add, metrics_score, score))\n",
    "            pred_y = pred_y[0].cpu().numpy()        ## (1, 512, 512)\n",
    "            pred_y = np.squeeze(pred_y, axis=0)     ## (512, 512)\n",
    "            pred_y = pred_y > 0.5\n",
    "            pred_y = np.array(pred_y, dtype=np.uint8)\n",
    "\n",
    "        \"\"\" Saving masks \"\"\"\n",
    "        ori_mask = mask_parse(mask)\n",
    "        pred_y = mask_parse(pred_y)\n",
    "        line = np.ones((size[1], 10, 3)) * 128\n",
    "\n",
    "        cat_images = np.concatenate(\n",
    "            [image, line, ori_mask, line, pred_y * 255], axis=1\n",
    "        )\n",
    "        cv2.imwrite(f\"results/{name}.png\", cat_images)\n",
    "\n",
    "    jaccard = metrics_score[0]/len(test_x)\n",
    "    f1 = metrics_score[1]/len(test_x)\n",
    "    recall = metrics_score[2]/len(test_x)\n",
    "    precision = metrics_score[3]/len(test_x)\n",
    "    acc = metrics_score[4]/len(test_x)\n",
    "    print(f\"Jaccard: {jaccard:1.4f} - F1: {f1:1.4f} - Recall: {recall:1.4f} - Precision: {precision:1.4f} - Acc: {acc:1.4f}\")\n",
    "\n",
    "    fps = 1/np.mean(time_taken)\n",
    "    print(\"FPS: \", fps)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255329f-3a10-4472-92e9-c274655e0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from operator import add\n",
    "import numpy as npzy\n",
    "from glob import glob\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\" Ground truth \"\"\"\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_true = y_true > 0.5\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    y_true = y_true.reshape(-1)\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_pred = y_pred.astype(np.uint8)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    score_jaccard = jaccard_score(y_true, y_pred)\n",
    "    score_f1 = f1_score(y_true, y_pred)\n",
    "    score_recall = recall_score(y_true, y_pred)\n",
    "    score_precision = precision_score(y_true, y_pred)\n",
    "    score_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return [score_jaccard, score_f1, score_recall, score_precision, score_acc]\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)    ## (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  ## (512, 512, 3)\n",
    "    return mask\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    seeding(42)\n",
    "\n",
    "    \"\"\" Folders \"\"\"\n",
    "    create_dir(\"results\")\n",
    "\n",
    "    \"\"\" Load dataset \"\"\"\n",
    "      \n",
    "    test_x = sorted(glob(\"C:/Users/hp/Desktop/aug_data/test/image/*\"))\n",
    "    test_y = sorted(glob(\"C:/Users/hp/Desktop/aug_data/test/mask/*\"))\n",
    "    \n",
    "    test_x = list(pd.Series(test_x).apply(lambda i:\"/\".join(i.split(\"\\\\\"))))\n",
    "    test_y = list(pd.Series(test_y).apply(lambda i:\"/\".join(i.split(\"\\\\\"))))\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    H = 512\n",
    "    W = 512\n",
    "    size = (W, H)\n",
    "    checkpoint_path = \"files/checkpoint.pth\"\n",
    "\n",
    "    \"\"\" Load the checkpoint \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = build_unet()\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    time_taken = []\n",
    "\n",
    "    for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
    "        \"\"\" Extract the name \"\"\"\n",
    "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        \"\"\" Reading image \"\"\"\n",
    "        image = cv2.imread(x, cv2.IMREAD_COLOR) ## (512, 512, 3)\n",
    "        ## image = cv2.resize(image, size)\n",
    "        x = np.transpose(image, (2, 0, 1))      ## (3, 512, 512)\n",
    "        x = x/255.0\n",
    "        x = np.expand_dims(x, axis=0)           ## (1, 3, 512, 512)\n",
    "        x = x.astype(np.float32)\n",
    "        x = torch.from_numpy(x)\n",
    "        x = x.to(device)\n",
    "\n",
    "        \"\"\" Reading mask \"\"\"\n",
    "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
    "        ## mask = cv2.resize(mask, size)\n",
    "        y = np.expand_dims(mask, axis=0)            ## (1, 512, 512)\n",
    "        y = y/255.0\n",
    "        y = np.expand_dims(y, axis=0)               ## (1, 1, 512, 512)\n",
    "        y = y.astype(np.float32)\n",
    "        y = torch.from_numpy(y)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \"\"\" Prediction and Calculating FPS \"\"\"\n",
    "            start_time = time.time()\n",
    "            pred_y = model(x)\n",
    "            pred_y = torch.sigmoid(pred_y)\n",
    "            total_time = time.time() - start_time\n",
    "            time_taken.append(total_time)\n",
    "\n",
    "\n",
    "            score = calculate_metrics(y, pred_y)\n",
    "            metrics_score = list(map(add, metrics_score, score))\n",
    "            pred_y = pred_y[0].cpu().numpy()        ## (1, 512, 512)\n",
    "            pred_y = np.squeeze(pred_y, axis=0)     ## (512, 512)\n",
    "            pred_y = pred_y > 0.5\n",
    "            pred_y = np.array(pred_y, dtype=np.uint8)\n",
    "\n",
    "        \"\"\" Saving masks \"\"\"\n",
    "        ori_mask = mask_parse(mask)\n",
    "        pred_y = mask_parse(pred_y)\n",
    "        line = np.ones((size[1], 10, 3)) * 128\n",
    "\n",
    "        cat_images = np.concatenate(\n",
    "            [image, line, ori_mask, line, pred_y * 255], axis=1\n",
    "        )\n",
    "        cv2.imwrite(f\"results/{name}.png\", cat_images)\n",
    "\n",
    "    jaccard = metrics_score[0]/len(test_x)\n",
    "    f1 = metrics_score[1]/len(test_x)\n",
    "    recall = metrics_score[2]/len(test_x)\n",
    "    precision = metrics_score[3]/len(test_x)\n",
    "    acc = metrics_score[4]/len(test_x)\n",
    "    print(f\"Jaccard: {jaccard:1.4f} - F1: {f1:1.4f} - Recall: {recall:1.4f} - Precision: {precision:1.4f} - Acc: {acc:1.4f}\")\n",
    "\n",
    "    fps = 1/np.mean(time_taken)\n",
    "    print(\"FPS: \", fps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
